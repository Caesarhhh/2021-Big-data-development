##### 设计思路

* 实操5拓展题主要在于在程序输出的同时动态改变user关键字的值，这里做成springboot的web项目，对外开放改变user关键字的接口

##### 测试入口

* job5\src\main\java\com\bigdata\week3\job5目录下Job5Application.java直接执行
* 使用postman或是浏览器对localhost:8022发送url指令启动程序或者改变user关键字
* localhost:8022/job/run：启动
* localhost:8022/job/change?user=吴夫子：将关键字改为吴夫子

##### 核心代码

###### controller

``` java
@RestController
@RequestMapping("/job5")
public class Controller {
    @RequestMapping("/run")
    public void run(){
        System.out.println("run");
        job5.run();
    }
    @RequestMapping("/stop")
    public void stop() throws InterruptedException {
        System.out.println("stop");
    }
    @RequestMapping("/change")
    public void change(@RequestParam("user")String user) throws InterruptedException {
        System.out.println("change:"+user);
        job5.changeUser(user);
    }
}
```

###### job5.scala

``` scala
object job5 {
  //需要监控的人名
  var user = "汤欣欣"
  var env = StreamExecutionEnvironment.getExecutionEnvironment
  val inputTopics: util.ArrayList[String] = new util.ArrayList[String]() {
    {
      add("mn_buy_ticket_1") //车票购买记录主题
      add("mn_hotel_stay_1") //酒店入住信息主题
      add("mn_monitoring_1") //监控系统数据主题
    }
  }
  val bootstrapServers = "bigdata35.depts.bingosoft.net:29035,bigdata36.depts.bingosoft.net:29036,bigdata37.depts.bingosoft.net:29037"

  def getUser(): String ={
    user
  }

  def changeUser(name:String): Unit ={
    user=name
  }
  def run(): Unit = {
    env.setParallelism(1)
    val kafkaProperties = new Properties()
    kafkaProperties.put("bootstrap.servers", bootstrapServers)
    kafkaProperties.put("group.id", UUID.randomUUID().toString)
    kafkaProperties.put("auto.offset.reset", "earliest")
    kafkaProperties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
    kafkaProperties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")
    val kafkaConsumer = new FlinkKafkaConsumer010[ObjectNode](inputTopics,
      new JSONKeyValueDeserializationSchema(true), kafkaProperties)
    kafkaConsumer.setCommitOffsetsOnCheckpoints(true)
    val inputKafkaStream = env.addSource(kafkaConsumer)
    inputKafkaStream.filter(x => x.get("value").get("username").asText("").equals(user)).map(x => {
      (x.get("metadata").get("topic").asText("") match {
        case "mn_monitoring_1"
        => x.get("value").get("found_time")
        case _ => x.get("value").get("buy_time")
      }, x)
    }).print()
    env.execute()
  }
}
```

##### 最终效果

* localhost:8022/job/run启动

<img src="https://caelog.oss-cn-beijing.aliyuncs.com/userdata/4/2021/06/19/267491d948d24ea390e9eb323345a92cimage-20210618213221136.png" width="600px" />

* localhost:8022/job/run启动后获取到汤欣欣的数据

<img src="https://caelog.oss-cn-beijing.aliyuncs.com/userdata/4/2021/06/19/b25d2404bc6e42a3916e030a672863a0image-20210618213247518.png" width="600px" />

* localhost:8022/job/change?user=吴夫子     将关键字改为吴夫子

<img src="https://caelog.oss-cn-beijing.aliyuncs.com/userdata/4/2021/06/19/d400faa7a8c34a7daa3032c8de18f33dimage-20210618213334590.png" width="600px" />

* localhost:8022/job/change?user=吴夫子     查到吴夫子的数据

<img src="https://caelog.oss-cn-beijing.aliyuncs.com/userdata/4/2021/06/19/fda634a601d342e29b5f23a7135d45c9image-20210618213405325.png" width="600px" />